{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwlin/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of daily_data_batch torch.Size([12, 15786, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torch/nn/modules/module.py:1128\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1128\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m/tmp2/cwlin/explainable_credit/codes.credit.relation.dev/NeuDP_GAT/codes/model.py:76\u001b[0m, in \u001b[0;36mCategoricalGraphAtt.forward\u001b[0;34m(self, daily_data_batch)\u001b[0m\n\u001b[1;32m     75\u001b[0m daily_data_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(daily_data_batch, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dim))\n\u001b[0;32m---> 76\u001b[0m daily_data_batch_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn(daily_data_batch)\n\u001b[1;32m     77\u001b[0m daily_data_batch_norm \u001b[39m=\u001b[39m daily_data_batch_norm\u001b[39m.\u001b[39mreshape([\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dim])\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torch/nn/modules/module.py:1128\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1128\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torch/nn/functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2421\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2422\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2423\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper__native_batch_norm)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/tmp2/cwlin/explainable_credit/codes.credit.relation.dev/NeuDP_GAT/codes/check_model_parameter.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.25.166.19/tmp2/cwlin/explainable_credit/codes.credit.relation.dev/NeuDP_GAT/codes/check_model_parameter.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# num_stock = len(pd.read_csv('/home/cwlin/explainable_credit/data/all_company_ids.csv', index_col=0).id.unique())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.25.166.19/tmp2/cwlin/explainable_credit/codes.credit.relation.dev/NeuDP_GAT/codes/check_model_parameter.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m ts_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m12\u001b[39m, \u001b[39m15786\u001b[39m, \u001b[39m14\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.25.166.19/tmp2/cwlin/explainable_credit/codes.credit.relation.dev/NeuDP_GAT/codes/check_model_parameter.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m summary(model, input_data\u001b[39m=\u001b[39;49mts_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[1;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[39m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/gnn4rec/lib/python3.9/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{\u001b[39;00mexecuted_layers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "data_dir = '/home/cwlin/explainable_credit/data/edge_file'\n",
    "cluster_setting = 'kmeans'\n",
    "n_cluster = 100\n",
    "inter_gat_hidn_dim=4\n",
    "intra_gat_hidn_dim=4\n",
    "lstm_hidn_dim=64\n",
    "device = torch.device('cuda:0')\n",
    "inner_edge_idx = torch.load(os.path.join(data_dir, f'{cluster_setting}_cluster_{n_cluster}', 'inner_edge_idx.pt'), map_location=device)\n",
    "outer_edge_idx = torch.load(os.path.join(data_dir, f'{cluster_setting}_cluster_{n_cluster}', 'outer_edge_idx.pt'), map_location=device)\n",
    "with open(os.path.join(f'{data_dir}/{cluster_setting}_cluster_{n_cluster}', 'company_to_sector_idx.pkl'), 'rb') as f:\n",
    "    company_to_sector_idx = pickle.load(f)\n",
    "\n",
    "model = CategoricalGraphAtt(14, 12, 8+1, lstm_hidn_dim, inter_gat_hidn_dim, intra_gat_hidn_dim, inner_edge_idx, outer_edge_idx, company_to_sector_idx, device)\n",
    "model_path = f'/home/ybtu/codes.credit.relation.dev/NeuDP_GAT/experiments/index/{cluster_setting}_{n_cluster}/NeuDP_GAT_12_index_lstm{lstm_hidn_dim}_intra{intra_gat_hidn_dim}_inter{inter_gat_hidn_dim}/last_weights/NeuDP_GAT_checkpoint_{n_cluster}.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# num_stock = len(pd.read_csv('/home/cwlin/explainable_credit/data/all_company_ids.csv', index_col=0).id.unique())\n",
    "ts_input = torch.randn(12, 15786, 14)\n",
    "\n",
    "summary(model, input_data=ts_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print model with hierarchy and parameters\n",
    "def print_model_with_hierarchy(model, indent=\"\"):\n",
    "    total_params = 0\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"{indent}{name}:\")\n",
    "        if list(module.children()):\n",
    "            child_params = print_model_with_hierarchy(module, indent + \"  \")\n",
    "            total_params += child_params\n",
    "        else:\n",
    "            for param_name, param in module.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    param_size = param.numel()\n",
    "                    total_params += param_size\n",
    "                    print(f\"{indent}  {param_name}: Parameters: {param_size}\")\n",
    "    return total_params\n",
    "\n",
    "# Print the model architecture with hierarchy and parameters\n",
    "# total_parameters = print_model_with_hierarchy(model)\n",
    "# print(f\"Total Parameters: {total_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn:\n",
      "  weight: Parameters: 168\n",
      "  bias: Parameters: 168\n",
      "sequence_encoder:\n",
      "  gru_cell:\n",
      "    x2h:\n",
      "      W: Parameters: 2688\n",
      "      b: Parameters: 192\n",
      "    h2h:\n",
      "      W: Parameters: 12288\n",
      "      b: Parameters: 192\n",
      "intra_gat:\n",
      "  lin_src:\n",
      "    weight: Parameters: 256\n",
      "cat_gat:\n",
      "  lin_src:\n",
      "    weight: Parameters: 16\n",
      "fusion:\n",
      "  weight: Parameters: 4608\n",
      "  bias: Parameters: 64\n",
      "logit_f:\n",
      "  weight: Parameters: 576\n",
      "  bias: Parameters: 9\n",
      "Total Parameters: 21225\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
