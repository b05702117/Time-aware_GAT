{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir', default='experiments/base_model',\n",
    "                    help=\"Directory containing params.json\")\n",
    "parser.add_argument('--data_dir', default='data/', help=\"Directory containing the dataset\")\n",
    "parser.add_argument('--label_type', default='cum', help=\"Label types, cum only or cum with forward label\")\n",
    "parser.add_argument('--restore_dir', default='None',\n",
    "                    help=\"Optional, directory containing weights to reload before training\")\n",
    "parser.add_argument('--device', default='0', help=\"CUDA_DEVICE\")\n",
    "\n",
    "# training settings\n",
    "parser.add_argument('--max_epoch', default=100, type=int)\n",
    "parser.add_argument('--patience', default=20, type=int)\n",
    "parser.add_argument('--batch_size', default=1, type=int)\n",
    "parser.add_argument('--learning_rate', default=1e-4, type=float, help='1e-3, 1e-4, 1e-5')\n",
    "parser.add_argument('--weight_decay', default=1e-5, type=float, help='1e-4, 1e-5, 1e-6, l2 regularization')\n",
    "parser.add_argument('--gamma', default=0.9, type=float, help='exponential learning rate scheduler, lr = lr_0 * gamma ^ epoch')\n",
    "\n",
    "# Set the random seed for the whole graph for reproductible experiments\n",
    "tf.set_random_seed(230)\n",
    "\n",
    "# Load the parameters from the experiment params.json file in model_dir\n",
    "args = parser.parse_args(['--model_dir', '../experiments/test_fim', '--data_dir', '/home/cwlin/explainable_credit/data/index_01_cum_for/index_fold_01/', '--label_type', 'cum',])\n",
    "\n",
    "\n",
    "# setting for individual device allocating\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' if args.device == 'cpu' else args.device\n",
    "\n",
    "json_path = os.path.join(args.model_dir, 'params.json')\n",
    "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "params = Params(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.num_epochs = args.max_epoch\n",
    "params.patience = args.patience\n",
    "params.batch_size = args.batch_size\n",
    "params.learning_rate = args.learning_rate\n",
    "params.weight_decay = args.weight_decay\n",
    "params.decay_rate = args.gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main_valid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tensorflow utility functions for training\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from model.utils import save_dict_to_json\n",
    "from model.evaluation import evaluate_sess\n",
    "\n",
    "\n",
    "def train_sess(sess, model_spec, num_steps, writer, params):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "\n",
    "    Args:\n",
    "        sess: (tf.Session) current session\n",
    "        model_spec: (dict) contains the graph operations or nodes needed for training\n",
    "        num_steps: (int) train for this number of batches\n",
    "        writer: (tf.summary.FileWriter) writer for summaries\n",
    "        params: (Params) hyperparameters\n",
    "    \"\"\"\n",
    "    # Get relevant graph operations or nodes needed for training\n",
    "    loss = model_spec['loss']\n",
    "    train_op = model_spec['train_op']\n",
    "    update_metrics = model_spec['update_metrics']\n",
    "    metrics = model_spec['metrics']\n",
    "    summary_op = model_spec['summary_op']\n",
    "    global_step = tf.train.get_global_step()\n",
    "\n",
    "    #pred_op = model_spec['pred']\n",
    "    #label_op = model_spec['label']\n",
    "    #para_op = model_spec['num_paras']\n",
    "\n",
    "    # Load the training dataset into the pipeline and initialize the metrics local variables\n",
    "    sess.run(model_spec['iterator_init_op'])\n",
    "    sess.run(model_spec['metrics_init_op'])\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(num_steps)\n",
    "    for i in t:\n",
    "        # Evaluate summaries for tensorboard only once in a while\n",
    "        if i % params.save_summary_steps == 0:\n",
    "            # Perform a mini-batch update\n",
    "            _, _, loss_val, summ, global_step_val = sess.run([train_op, update_metrics, loss,\n",
    "                                                              summary_op, global_step])\n",
    "\n",
    "            ## Debug\n",
    "            #_, _, loss_val, summ, global_step_val, n_paras = sess.run([train_op, update_metrics, loss,\n",
    "            #                                                  summary_op, global_step, para_op])\n",
    "            #np.set_printoptions(precision=3)\n",
    "            #print(\"# of paras: {}\".format(n_paras))\n",
    "            #print(\" pred: {}\".format(pred))\n",
    "            #print(\"label: {}\".format(label))\n",
    "\n",
    "            # Write summaries for tensorboard\n",
    "            writer.add_summary(summ, global_step_val)\n",
    "        else:\n",
    "            _, _, loss_val = sess.run([train_op, update_metrics, loss])\n",
    "        # Log the loss in the tqdm progress bar\n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_val))\n",
    "\n",
    "\n",
    "    metrics_values = {k: v[0] for k, v in metrics.items()}\n",
    "    metrics_val = sess.run(metrics_values)\n",
    "    aucs = [v for k, v in metrics_val.items() if 'auc_' in k]\n",
    "    metrics_val['auc'] = sum(aucs)/len(aucs)\n",
    "    metrics_string = \"; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_val.items())\n",
    "    logging.info(\"- Train metrics: \" + metrics_string)\n",
    "\n",
    "\n",
    "def train_and_evaluate(train_model_spec, eval_model_spec, model_dir, params, restore_from=None):\n",
    "    \"\"\"Train the model and evaluate every epoch.\n",
    "\n",
    "    Args:\n",
    "        train_model_spec: (dict) contains the graph operations or nodes needed for training\n",
    "        eval_model_spec: (dict) contains the graph operations or nodes needed for evaluation\n",
    "        model_dir: (string) directory containing config, weights and log\n",
    "        params: (Params) contains hyperparameters of the model.\n",
    "                Must define: num_epochs, train_size, batch_size, eval_size, save_summary_steps\n",
    "        restore_from: (string) directory or file containing weights to restore the graph\n",
    "    \"\"\"\n",
    "    # Initialize tf.Saver instances to save weights during training\n",
    "    last_saver = tf.train.Saver() # will keep last 5 epochs\n",
    "    best_saver = tf.train.Saver(max_to_keep=1)  # only keep 1 best checkpoint (best on eval)\n",
    "    begin_at_epoch = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize model variables\n",
    "        sess.run(train_model_spec['variable_init_op'])\n",
    "\n",
    "        # Reload weights from directory if specified\n",
    "        if restore_from is not None:\n",
    "            logging.info(\"Restoring parameters from {}\".format(restore_from))\n",
    "            if os.path.isdir(restore_from):\n",
    "                restore_from = tf.train.latest_checkpoint(restore_from)\n",
    "                begin_at_epoch = int(restore_from.split('-')[-1])\n",
    "            last_saver.restore(sess, restore_from)\n",
    "\n",
    "        # For tensorboard (takes care of writing summaries to files)\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(model_dir, 'train_summaries'), sess.graph)\n",
    "        eval_writer = tf.summary.FileWriter(os.path.join(model_dir, 'eval_summaries'), sess.graph)\n",
    "\n",
    "        best_eval_acc = 0.0\n",
    "        for epoch in range(begin_at_epoch, begin_at_epoch + params.num_epochs):\n",
    "            # Run one epoch\n",
    "            logging.info(\"Epoch {}/{}\".format(epoch + 1, begin_at_epoch + params.num_epochs))\n",
    "            # Compute number of batches in one epoch (one full pass over the training set)\n",
    "            num_steps = (params.train_size + params.batch_size - 1) // params.batch_size\n",
    "            train_sess(sess, train_model_spec, num_steps, train_writer, params)\n",
    "\n",
    "            # Save weights\n",
    "            last_save_path = os.path.join(model_dir, 'last_weights', 'after-epoch')\n",
    "            last_saver.save(sess, last_save_path, global_step=epoch + 1)\n",
    "\n",
    "            # Evaluate for one epoch on validation set\n",
    "            num_steps = (params.eval_size + params.batch_size - 1) // params.batch_size\n",
    "            metrics = evaluate_sess(sess, eval_model_spec, num_steps, eval_writer)\n",
    "\n",
    "\n",
    "            # If best_eval, best_save_path\n",
    "            eval_acc = metrics['auc']\n",
    "            if eval_acc >= best_eval_acc:\n",
    "                # Store new best accuracy\n",
    "                best_eval_acc = eval_acc\n",
    "                # Save weights\n",
    "                best_save_path = os.path.join(model_dir, 'best_weights', 'after-epoch')\n",
    "                best_save_path = best_saver.save(sess, best_save_path, global_step=epoch + 1)\n",
    "                logging.info(\"- Found new best auc, saving in {}\".format(best_save_path))\n",
    "                # Save best eval metrics in a json file in the model directory\n",
    "                best_json_path = os.path.join(model_dir, \"metrics_eval_best_weights.json\")\n",
    "                save_dict_to_json(metrics, best_json_path)\n",
    "\n",
    "            # Save latest eval metrics in a json file in the model directory\n",
    "            last_json_path = os.path.join(model_dir, \"metrics_eval_last_weights.json\")\n",
    "            save_dict_to_json(metrics, last_json_path)\n",
    "\n",
    "## Check that we are not overwriting some previous experiment\n",
    "## Comment these lines if you are developing your model and don't care about overwritting\n",
    "#model_dir_has_best_weights = os.path.isdir(os.path.join(args.model_dir, \"best_weights\"))\n",
    "#overwritting = model_dir_has_best_weights and args.restore_dir is None\n",
    "#assert not overwritting, \"Weights found in model_dir, aborting to avoid overwrite\"\n",
    "\n",
    "# Set the logger\n",
    "set_logger(os.path.join(args.model_dir, 'train.log'))\n",
    "\n",
    "# Create the input data pipeline\n",
    "logging.info(\"Creating the datasets...\")\n",
    "\n",
    "## CW: train_subset and valid_subset are used for the early stopping epoch and patience\n",
    "# train_data = \"train_{}.gz\".format(params.label_type)\n",
    "train_data = \"train_subset_{}.gz\".format(params.label_type)\n",
    "# test_data  =  \"test_{}.gz\".format(params.label_type)\n",
    "test_data  =  \"valid_subset_{}.gz\".format(params.label_type)\n",
    "# Paths to data\n",
    "train_data = os.path.join(args.data_dir, train_data)\n",
    "eval_data  = os.path.join(args.data_dir, test_data)\n",
    "# skip header\n",
    "params.train_size = int(os.popen('zcat ' + train_data + '|wc -l').read()) - 1\n",
    "params.eval_size = int(os.popen('zcat ' + eval_data  + '|wc -l').read()) - 1\n",
    "logging.info('Train size: {}, Eval size: {}'.format(params.train_size, params.eval_size))\n",
    "\n",
    "# CW: For setting the decay_steps to the number of batches in an epoch. This way, the learning rate would be decayed once per epoch, just like in PyTorch.\n",
    "num_batches_per_epoch = math.ceil(params.train_size / params.batch_size)\n",
    "params.decay_steps = int(num_batches_per_epoch * params.num_epochs)\n",
    "\n",
    "# Create the two iterators over the two datasets\n",
    "train_inputs = input_fn(True, train_data, params)\n",
    "eval_inputs = input_fn(False, eval_data, params)\n",
    "logging.info(\"- done.\")\n",
    "\n",
    "# Define the models (2 different set of nodes that share weights for train and eval)\n",
    "logging.info(\"Creating the model...\")\n",
    "train_model_spec = model_fn(True, train_inputs, params)\n",
    "eval_model_spec = model_fn(False, eval_inputs, params, reuse=True)\n",
    "logging.info(\"- done.\")\n",
    "\n",
    "if args.restore_dir != \"None\":\n",
    "    restore_dir = os.path.join(args.model_dir, args.restore_dir)\n",
    "else:\n",
    "    restore_dir = None\n",
    "\n",
    "# Train the model\n",
    "logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "train_and_evaluate(train_model_spec, eval_model_spec, args.model_dir, params, restore_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp_credit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
